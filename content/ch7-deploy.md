# 线上推理与部署

本节我们介绍与模型上线部署相关的知识。以我所在公司为例，当我入职熟悉工作时，很快就发现很多算法都是以「项目」为粒度进行开发的。也就是说，有一个项目A，然后里面围绕着这个项目进行一系列工作，从模型训练到最终上线。这导致一个什么状况呢，那就是每个项目都有一套Python环境，都会占用一个GPU卡进行推理。优点是简单、相对独立，项目之间完全没有关联；缺点是资源浪费，代码冗余。这大概是大部分算法工作的情况，其最主要的原因就是算法大多数时候提供的是一个「功能」，而不是一个「产品」，它往往依赖前后端，尤其是后端，作为后端的后端存在。这就导致算法服务无论是开发还是上线，都会相对不那么规范。当然，另一个原因就是绝大部分的算法工程师业务代码水平不是很好（什么是好代码我们下节会介绍），毕竟还是算法工作为主。本节，我们就主要围绕与整体部署展开，大概包括以下内容：

- 选择合适的推理方式
- 统一视角看推理部署
- 并发并行与性能优化

## 选择合适的推理方式

推理，简单来说，就是输入一系列浮点数，经过很多浮点数计算后，输出对应的一系列浮点数。如果我们从语言环境依赖角度看，可以分成两大类：

- 语言环境依赖的
- 语言环境独立的

前者又可以分成多种不同的语言，比如以大家熟悉的Python来看，我们可以使用Pytorch或Tensorflow直接加载模型，并提供服务API，但需要依赖Pytorch或Tensorflow的环境。再比如Java的PMML或Pytorch的C++前端API等也是类似的，需要依赖语言环境，或者说与该语言编写的其他模块内嵌在一块。

后者有两种方式，一种是将模型转成一种推理的中间格式，比如onnxruntime或使用TensorRT。还有一种就是使用推理框架将其部署为HTTP/RPC服务，当然框架背后会对模型做很多优化。

那么，在上面这些不同的方式中，最简单的就是最后一种了，主要体现在以下几个方面：

- 不需要自己做算子深度优化
- 不需要自己做服务优化（异步、Batch、并行等）
- 使用简单而且与环境解耦
- 横向扩展简单
- 集中管理提高资源效率

我们本节就以这类方式为主，以Triton为例来介绍，它非常适用于经典的C/S架构。当然，事无绝对，如果要做端侧推理，或某些私有化场景不支持这种方式，那就需要针对特定情况进行开发了。

## 统一视角看推理部署

很多人习惯将模型和项目绑在一起看，其实这是不必要的。刚刚我们已经提到过了，其实无论是什么模型，都只是一堆数字，不同的只是输入和输出。因此，我们完全可以将「纯模型」的东西全部放在一起整合处理。这也是我们推荐使用Triton的原因，它可以很好地帮助我们完成这一任务。这里唯一要注意的就是，将任何与「业务」相关的逻辑抽离出去，包括输入文本到id之间的tokenize过程。也就是说，模型服务只接受input_ids这样的输入，而不是原始的文本。换句话说，将统一的模型服务就当做模型本身，输入输出都是模型本身的东西，不需要有任何前后处理。

在我司的工程实践中，使用类似的方法节省资源50%以上，部署效率提升5倍，更加重要的是，维护变得超级简单。每次新业务功能发布时，模型并不会重新加载，部署就一行命令，30秒内多个环境全部搞定。单卡可支持多个模型推理，而且可自动伸缩灵活调整配置，而这一切和业务完全解耦。模型的更新只需上传模型文件即可自动热更，而且同一模型可以支持多个版本。为了应用侧更方便地使用模型服务，我们专门写了相应的客户端，用户（模型服务调用方，一般是其他算法工程师）只需在参数中指定模型和版本，并提供模型的输入即可自动路由到对应模型获得输出。在整个服务过程中，我们不需要关心模型是什么，提供什么输出，需要什么输入，我们只提供统一的控制参数和服务。

题外话，还有个地方可能不太方便，就是费用分摊。很多时候我们服务资源的费用可能需要分摊到各个不同的调用方，我们也不例外。对于这种情况，我们在调用测做了调用日志记录。而且这里不一定是直接的调用测，可是在与业务相关的那一层做了处理。举个例子，我们有一个NER模型，为了便于其他算法工程师使用（并减少代码冗余），我们会自己先写一个Ner模块（内部私有Pip包）。这里没有任何业务相关的内容，它的主要参数就是文本，输出是一个个实体（有自己的数据结构）。其他算法同事（或非算法同事）会在自己的项目中直接import这个包就好了，他们在自己的项目中进行调用的记录。我们可以将这个Ner包视作protected，只有AI中心内部可以使用，其他人则因为我们做了权限控制，无法安装使用。

通过这个案例，我们希望大家能对推理部署有一个全新的认识，它更多的是一种整体架构和流程的设计，而不是Naive的包一个FastAPI或Flask接口就完事了。总结来看，上面我们重点强调的是模块化、各种级别的解耦和控制，以及架构分层。我们也简单提到了不同层级的权限控制（当然这不是算法的核心，但它很重要）。其实，在实践中还会更复杂一些，还是以我们自己的实践为例，起码还包括：

- 多环境部署。一般分测试、预发和正式三个环境。彼此有些模块是共享的，但业务相关的一定是隔离的。
- 压测。这是个有意思的主题，如果你使用requests进行压测，建议重新研究一下这方面内容。为了便于内部压测，我们专门写了一个压测工具的封装，使用方只需要填写配置文件，然后一行命令就开始压测，结束后会自动输出本次压测报告。
- 服务降级和容错。我们在编写模块包时会考虑到整个模型服务挂掉的极端情况。当我们的模型服务超时时，我们会使用规则或简单的策略返回结果，此时调用方服务并不会因此受到很大影响（可能效果会有所降低）。对于直接调用模型服务的算法同事，我们也在文档中强调了这一机制，希望他们能够提供整个模型服务挂掉时的容错和降级机制。
- 报警和通知。服务会出问题，我们需要第一时间得到通知。为此，我们专门编写了一个监控模块，用于当服务出现状况时第一时间推送消息给我们。这里主要是对服务和错误进行分级，我们对prod环境的错误非常敏感。

项目上线运行一年多，没有出过问题。

## 并发并行与性能优化

最后，我们简单谈一下关于并发、并行和性能优化。这部分内容主题过于宏大，我们只能简单提供一些视角给大家参考。大家起码要明白并发、并行、分布式几个基本概念，以及性能优化是在优化什么。

并发是同时处理多件事情，是多个任务不停轮换抢占CPU时间片，让用户感觉起来好像多个任务是在同时执行一样。常用的并发方案是多线程（进程）和异步。前者是将任务丢给不同的子线程（进程），尤其适合于IO型任务，由于IO时间一般大于CPU时间，在IO阻塞期间CPU可以完成任务执行。比较经典的异步方案是回调和协程。回调基于事件轮询，单线程可以有很好的并发能力，比如NodeJS的异步回调。协程本质是控制流的让出和恢复，协程基于线程，比线程更轻量，没有昂贵的内核调度，效率更高。Python、JavaScript、Ruby等也实现了协程（通过 `async def` 使用），还比如go语言的go程。实际使用时线程和协程经常可以结合使用，比如如果你用过gunicorn或uvicorn的话，就知道在启动服务时可以使用多线程参数启动多个线程；如果代码里同时有异步支持，那就是两者结合的案例了。总的来说，协程更加轻量，没有全局锁，非阻塞，可以执行非常大量的任务；而线程有GIL，阻塞型IO，一般100-1000个任务（C10K问题）。协程由线程调度，内存占用更小，上下文切换开销更小；线程由进程（系统内核）调度，导致结果随机，以及多线程带来的安全问题。多线程编程会更加复杂，涉及竞态条件、临界区、同步互斥、锁等。

并发其实更多体现在IO任务上，和算法推理其实关系不太大。与算法直接相关的其实是并行。并行是同时执行多个任务，不是看起来是同时，而是真正的同时。传统的CPU一般会利用多核进行并行，也就是常见的SIMD（单指令多数据）结构。其实并行分两种情况：任务并行和数据并行，数据并行更加简单，所以后面成了主流。现在我们从算法模型的角度来看，并行其实包括：数据并行、Tensor并行和pipeline并行，也就是咱们常听到的DP、TP（或MP）和PP。DP下，模型分布到各个卡上，各卡分别执行不同数据，比如Pytorch的DDP就是这种做法。如果模型放不到单卡上，这时候就需要TP或PP了，先说TP，它就是把Tensor切成多个chunk，将它们分别分布到指定卡上。PP是按层拆分模型，因此模型只有一层或几层放置在单个卡上。因为模型推理是实实在在的CPU/GPU任务，此时你会发现开启异步模式可能并不会有太多性能提升。接下来我们简单了解一下分布式。分布式一般涉及到集群（多节点），它也是一种并行的方案。如果只是单纯横向扩展，不涉及节点间的通信，一般都比较简单。但如果涉及到数据同步、锁等内容，就会变得比较复杂。

其实并发和并行也算是一种优化，尤其是并行。不过我们这里说的优化主要是模型或模块本身性能的优化。量化也是常用的策略，主要用来降低显存占用，比如半精度、FP16、8bit、甚至4bit等，当然也能提升效率。当然，还有剪枝、蒸馏这些常用手段，它们都是把模型本身变得更快。还可以对具体的模块进行优化（尤其是Self-Attention），比如flash-attention、xformer、SparseTransformer等。或者使用CUDA或C++对底层算子优化，比如英伟达的FasterTransformer。大部分情况下，我们并不需要做相关的优化，开源的内容足以应付99.9%的情况了。但如果是一些特殊场景（比如百万级别并发）或特殊设备（比如一些端侧设备），则可能需要针对性地进行优化。

总的来说，优化需要考虑具体情况，并权衡成本收益。如果增加一个实例或加一个节点能满足需求，那就不要费劲巴拉折腾。当然，这不是说我们不要学习研究这方面知识。只是说，在生产环境或企业实际场景中，以最小成本、最高效率解决问题是非常重要的。用户从来不关心我们用的什么技术，同样，使用你服务的同事也从来不会关心你用了什么方法。